# üìä Gu√≠a Completa para Dami√°n - Dashboard Streamlit

> **Estado del Proyecto**: ‚úÖ Backend completado (Rivaldo)  
> **Tu Responsabilidad**: Crear el frontend/dashboard de visualizaci√≥n  
> **Fecha**: Febrero 1, 2026

---

## üìã √çndice

1. [Situaci√≥n Actual](#situaci√≥n-actual)
2. [Tu Misi√≥n](#tu-misi√≥n)
3. [Pasos Detallados](#pasos-detallados)
4. [Estructura de Archivos](#estructura-de-archivos)
5. [Conexi√≥n a la Base de Datos](#conexi√≥n-a-la-base-de-datos)
6. [C√≥digo Base para Empezar](#c√≥digo-base-para-empezar)
7. [Pruebas y Validaci√≥n](#pruebas-y-validaci√≥n)

---

## üîç Situaci√≥n Actual

El backend est√° **100% funcional**:

‚úÖ **MQTT Broker** (Mosquitto local)  
‚úÖ **Publisher** - Publica datos cada 2 segundos:
  - T√≥pico: `lake/raw/int` ‚Üí Valores enteros (0-1000)
  - T√≥pico: `lake/raw/float` ‚Üí Valores flotantes (0-100)

‚úÖ **Subscriber** - Recibe y almacena en PostgreSQL:
  - Tabla: `lake_raw_data_int` (96 registros ‚úÖ)
  - Tabla: `lake_raw_data_float` (98 registros ‚úÖ)

**Base de Datos PostgreSQL:**
- Host: `postgres_db` (dentro de Docker) o `localhost:5432` (desde afuera)
- Usuario: `user`
- Contrase√±a: `password`
- Base de datos: `sensordata`

---

## üéØ Tu Misi√≥n

Crear un **dashboard interactivo con Streamlit** que:

1. ‚úèÔ∏è **Visualice datos en tiempo real** desde la base de datos PostgreSQL
2. üìà **Muestre gr√°ficas de series de tiempo** para ambos tipos de datos
3. üéõÔ∏è **Permita filtrar por rango de tiempo** (√∫ltimos 5 min, 1 hora, 24 horas, personalizado)
4. üìä **Muestre estad√≠sticas** (promedio, m√°ximo, m√≠nimo, conteo)
5. üé® **Dise√±o limpio e intuitivo** con pesta√±as/p√°ginas

---

## üìù Pasos Detallados

### Paso 1: Preparar el Entorno

**1.1. Verifica que todo est√© corriendo:**

```bash
docker-compose ps
```

Deber√≠as ver:
- ‚úÖ mosquitto ‚Üí UP
- ‚úÖ postgres_db ‚Üí UP
- ‚úÖ subscriber ‚Üí UP

**1.2. Si algo no est√° corriendo:**

```bash
docker-compose down
docker-compose up -d
```

Espera 10 segundos a que PostgreSQL est√© listo.

---

### Paso 2: Crear la Estructura del Proyecto Streamlit

**2.1. Los archivos ya existen en `streamlit_app/`:**

```
streamlit_app/
‚îú‚îÄ‚îÄ Dockerfile                 # ‚úÖ Ya existe
‚îú‚îÄ‚îÄ requirement.txt           # ‚ö†Ô∏è Revisar (tiene typo: "requirement" en lugar de "requirements")
‚îú‚îÄ‚îÄ requirements.txt          # ‚úÖ Ya existe
‚îú‚îÄ‚îÄ app.py                    # üö´ NECESITAS CREAR ESTO
‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ page1_datos_en_vivo.py     # üö´ NECESITAS CREAR
‚îÇ   ‚îî‚îÄ‚îÄ page2_estadisticas.py      # üö´ NECESITAS CREAR
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ db_connection.py      # üö´ NECESITAS CREAR
‚îî‚îÄ‚îÄ styles/
    ‚îî‚îÄ‚îÄ custom.css            # Opcional (estilos personalizados)
```

**2.2. Verifica que `requirements.txt` est√© correcto:**

El archivo `streamlit_app/requirements.txt` debe contener:

```txt
streamlit==1.28.1
pandas==2.0.0
plotly==5.17.0
psycopg2-binary==2.9.9
sqlalchemy==2.0.23
python-dotenv==1.0.0
pyarrow==14.0.1
```

Si no est√°, cr√©alo con este contenido.

---

### Paso 3: Crear el M√≥dulo de Conexi√≥n a Base de Datos

**3.1. Crea el archivo `streamlit_app/utils/db_connection.py`:**

```python
import os
import psycopg2
import pandas as pd
from dotenv import load_dotenv
import streamlit as st

# Cargar variables de entorno
load_dotenv()

@st.cache_resource
def get_db_connection():
    """
    Obtiene una conexi√≥n a la base de datos PostgreSQL.
    Usa st.cache_resource para evitar crear m√∫ltiples conexiones.
    """
    try:
        connection = psycopg2.connect(
            host=os.getenv("DB_HOST", "localhost"),
            port=os.getenv("DB_PORT", "5432"),
            user=os.getenv("DB_USER", "user"),
            password=os.getenv("DB_PASSWORD", "password"),
            database=os.getenv("DB_NAME", "sensordata")
        )
        return connection
    except Exception as e:
        st.error(f"‚ùå Error conectando a la base de datos: {e}")
        return None

def query_data(query, params=None):
    """
    Ejecuta una consulta SQL y retorna los resultados como DataFrame.
    """
    connection = get_db_connection()
    if connection is None:
        return None
    
    try:
        df = pd.read_sql(query, connection, params=params)
        return df
    except Exception as e:
        st.error(f"‚ùå Error ejecutando consulta: {e}")
        return None

def get_int_data(hours=1):
    """
    Obtiene datos de tipo entero de las √∫ltimas N horas.
    """
    query = """
    SELECT id, topic, value, timestamp
    FROM lake_raw_data_int
    WHERE timestamp >= NOW() - INTERVAL '%s hours'
    ORDER BY timestamp ASC
    """
    return query_data(query, (hours,))

def get_float_data(hours=1):
    """
    Obtiene datos de tipo flotante de las √∫ltimas N horas.
    """
    query = """
    SELECT id, topic, value, timestamp
    FROM lake_raw_data_float
    WHERE timestamp >= NOW() - INTERVAL '%s hours'
    ORDER BY timestamp ASC
    """
    return query_data(query, (hours,))

def get_stats_int(hours=1):
    """
    Obtiene estad√≠sticas de datos enteros.
    """
    query = """
    SELECT 
        COUNT(*) as total,
        AVG(value) as promedio,
        MIN(value) as minimo,
        MAX(value) as maximo,
        STDDEV(value) as desv_std
    FROM lake_raw_data_int
    WHERE timestamp >= NOW() - INTERVAL '%s hours'
    """
    return query_data(query, (hours,))

def get_stats_float(hours=1):
    """
    Obtiene estad√≠sticas de datos flotantes.
    """
    query = """
    SELECT 
        COUNT(*) as total,
        AVG(value) as promedio,
        MIN(value) as minimo,
        MAX(value) as maximo,
        STDDEV(value) as desv_std
    FROM lake_raw_data_float
    WHERE timestamp >= NOW() - INTERVAL '%s hours'
    """
    return query_data(query, (hours,))
```

**3.2. Crea `streamlit_app/utils/__init__.py`:** (archivo vac√≠o)

```python
# Este archivo hace que utils sea un m√≥dulo de Python
```

---

### Paso 4: Crear la P√°gina Principal (app.py)

**4.1. Crea `streamlit_app/app.py`:**

```python
import streamlit as st
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from utils.db_connection import get_int_data, get_float_data, get_stats_int, get_stats_float

# Configuraci√≥n de Streamlit
st.set_page_config(
    page_title="IoT Dashboard - MQTT Data",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos personalizados
st.markdown("""
    <style>
    .main-title {
        color: #1f77b4;
        text-align: center;
        font-size: 2.5em;
        margin-bottom: 20px;
    }
    .status-online {
        color: #2ecc71;
        font-weight: bold;
    }
    .status-offline {
        color: #e74c3c;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo
st.markdown('<div class="main-title">üìä Dashboard IoT - MQTT Data Ingestion</div>', unsafe_allow_html=True)

# Barra lateral - Filtros
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    time_range = st.selectbox(
        "Rango de tiempo",
        options=[
            ("√öltimos 5 minutos", 0.083),  # 5 min ‚âà 0.083 horas
            ("√öltima 1 hora", 1),
            ("√öltimas 4 horas", 4),
            ("√öltimas 24 horas", 24),
            ("√öltimos 7 d√≠as", 168)
        ],
        format_func=lambda x: x[0]
    )
    
    hours_to_fetch = time_range[1]
    
    # Bot√≥n para refrescar
    if st.button("üîÑ Refrescar Datos", use_container_width=True):
        st.cache_resource.clear()
        st.rerun()
    
    st.markdown("---")
    st.info("‚ÑπÔ∏è Los datos se actualizan cada 2 segundos en el backend.\nHaz clic en 'Refrescar' para ver cambios.")

# Tabs principales
tab1, tab2, tab3 = st.tabs(["üìà Datos en Vivo", "üìä Estad√≠sticas", "‚ÑπÔ∏è Informaci√≥n"])

# ===================== TAB 1: DATOS EN VIVO =====================
with tab1:
    col1, col2 = st.columns(2)
    
    # Gr√°fica de Datos Enteros
    with col1:
        st.subheader("üî¢ Datos Enteros (Integer)")
        
        df_int = get_int_data(hours_to_fetch)
        
        if df_int is not None and not df_int.empty:
            st.write(f"üìç Registros: {len(df_int)}")
            
            # Gr√°fica interactiva con Plotly
            fig_int = go.Figure()
            fig_int.add_trace(go.Scatter(
                x=df_int['timestamp'],
                y=df_int['value'],
                mode='lines+markers',
                name='Datos Enteros',
                line=dict(color='#1f77b4', width=2),
                marker=dict(size=6)
            ))
            
            fig_int.update_layout(
                title="Serie de Tiempo - Valores Enteros",
                xaxis_title="Tiempo",
                yaxis_title="Valor",
                hovermode='x unified',
                height=400
            )
            
            st.plotly_chart(fig_int, use_container_width=True)
            
            # Mostrar √∫ltimos registros
            with st.expander("üìã Ver √∫ltimos registros"):
                st.dataframe(df_int.tail(10), use_container_width=True)
        else:
            st.warning("No hay datos disponibles para el rango seleccionado")
    
    # Gr√°fica de Datos Flotantes
    with col2:
        st.subheader("üî¢ Datos Flotantes (Float)")
        
        df_float = get_float_data(hours_to_fetch)
        
        if df_float is not None and not df_float.empty:
            st.write(f"üìç Registros: {len(df_float)}")
            
            # Gr√°fica interactiva con Plotly
            fig_float = go.Figure()
            fig_float.add_trace(go.Scatter(
                x=df_float['timestamp'],
                y=df_float['value'],
                mode='lines+markers',
                name='Datos Flotantes',
                line=dict(color='#ff7f0e', width=2),
                marker=dict(size=6)
            ))
            
            fig_float.update_layout(
                title="Serie de Tiempo - Valores Flotantes",
                xaxis_title="Tiempo",
                yaxis_title="Valor",
                hovermode='x unified',
                height=400
            )
            
            st.plotly_chart(fig_float, use_container_width=True)
            
            # Mostrar √∫ltimos registros
            with st.expander("üìã Ver √∫ltimos registros"):
                st.dataframe(df_float.tail(10), use_container_width=True)
        else:
            st.warning("No hay datos disponibles para el rango seleccionado")

# ===================== TAB 2: ESTAD√çSTICAS =====================
with tab2:
    st.subheader("üìä Estad√≠sticas por Tipo de Dato")
    
    col1, col2 = st.columns(2)
    
    # Estad√≠sticas de Enteros
    with col1:
        st.markdown("### üî¢ Datos Enteros")
        
        stats_int = get_stats_int(hours_to_fetch)
        
        if stats_int is not None and not stats_int.empty:
            stats_int = stats_int.iloc[0]
            
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric("Total", f"{int(stats_int['total'])}", help="Total de registros")
                st.metric("Promedio", f"{stats_int['promedio']:.2f}", help="Valor promedio")
            
            with metric_col2:
                st.metric("M√≠nimo", f"{int(stats_int['minimo'])}", help="Valor m√≠nimo")
                st.metric("M√°ximo", f"{int(stats_int['maximo'])}", help="Valor m√°ximo")
            
            st.metric("Desv. Est√°ndar", f"{stats_int['desv_std']:.2f}", help="Desviaci√≥n est√°ndar")
        else:
            st.warning("No hay datos para calcular estad√≠sticas")
    
    # Estad√≠sticas de Flotantes
    with col2:
        st.markdown("### üî¢ Datos Flotantes")
        
        stats_float = get_stats_float(hours_to_fetch)
        
        if stats_float is not None and not stats_float.empty:
            stats_float = stats_float.iloc[0]
            
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric("Total", f"{int(stats_float['total'])}", help="Total de registros")
                st.metric("Promedio", f"{stats_float['promedio']:.2f}", help="Valor promedio")
            
            with metric_col2:
                st.metric("M√≠nimo", f"{stats_float['minimo']:.2f}", help="Valor m√≠nimo")
                st.metric("M√°ximo", f"{stats_float['maximo']:.2f}", help="Valor m√°ximo")
            
            st.metric("Desv. Est√°ndar", f"{stats_float['desv_std']:.2f}", help="Desviaci√≥n est√°ndar")
        else:
            st.warning("No hay datos para calcular estad√≠sticas")

# ===================== TAB 3: INFORMACI√ìN =====================
with tab3:
    st.markdown("""
    ## üìã Informaci√≥n del Proyecto
    
    ### Arquitectura
    
    Este dashboard se conecta a un sistema IoT que utiliza:
    
    - **MQTT Broker**: Eclipse Mosquitto (local en Docker)
    - **Publisher**: Genera datos cada 2 segundos
      - T√≥pico `lake/raw/int`: Valores enteros (0-1000)
      - T√≥pico `lake/raw/float`: Valores decimales (0-100)
    - **Subscriber**: Recibe datos y los almacena en PostgreSQL
    - **Base de Datos**: PostgreSQL 13
      - Tabla: `lake_raw_data_int`
      - Tabla: `lake_raw_data_float`
    
    ### Variables de Entorno
    
    El dashboard usa las siguientes variables (en `.env`):
    
    ```
    DB_HOST=localhost
    DB_PORT=5432
    DB_USER=user
    DB_PASSWORD=password
    DB_NAME=sensordata
    ```
    
    ### Filtros Disponibles
    
    - **√öltimos 5 minutos**: Muestra solo datos de los √∫ltimos 5 minutos
    - **√öltima 1 hora**: Muestra datos de la √∫ltima hora
    - **√öltimas 4 horas**: Muestra datos de las √∫ltimas 4 horas
    - **√öltimas 24 horas**: Muestra datos del √∫ltimo d√≠a
    - **√öltimos 7 d√≠as**: Muestra datos de la √∫ltima semana
    
    ### Estad√≠sticas Mostradas
    
    Para cada tipo de dato:
    - **Total**: Cantidad de registros
    - **Promedio**: Valor medio
    - **M√≠nimo**: Valor m√°s bajo
    - **M√°ximo**: Valor m√°s alto
    - **Desv. Est√°ndar**: Desviaci√≥n est√°ndar
    """)
```

---

### Paso 5: Crear P√°ginas Adicionales (Opcional pero Recomendado)

**5.1. Crea `streamlit_app/pages/__init__.py`:** (archivo vac√≠o)

```python
# Este archivo hace que pages sea un m√≥dulo de Python
```

**5.2. Crea `streamlit_app/pages/page1_datos_en_vivo.py`:**

```python
import streamlit as st
from utils.db_connection import get_int_data, get_float_data
import plotly.graph_objects as go

st.title("üìà Datos en Vivo")

st.write("""
Este p√°gina muestra los datos en tiempo real que est√°n siendo capturados 
por el sistema MQTT y almacenados en la base de datos PostgreSQL.
""")

# Selector de horas
hours = st.slider("√öltimas N horas", min_value=0.083, max_value=168, value=1.0, step=0.083)

col1, col2 = st.columns(2)

with col1:
    st.subheader("Datos Enteros")
    df_int = get_int_data(hours)
    if df_int is not None and not df_int.empty:
        st.metric("Total de registros", len(df_int))
        st.dataframe(df_int, use_container_width=True)

with col2:
    st.subheader("Datos Flotantes")
    df_float = get_float_data(hours)
    if df_float is not None and not df_float.empty:
        st.metric("Total de registros", len(df_float))
        st.dataframe(df_float, use_container_width=True)
```

**5.3. Crea `streamlit_app/pages/page2_estadisticas.py`:**

```python
import streamlit as st
from utils.db_connection import get_stats_int, get_stats_float
import pandas as pd

st.title("üìä Estad√≠sticas Detalladas")

st.write("""
An√°lisis estad√≠stico completo de los datos capturados.
""")

hours = st.slider("√öltimas N horas", min_value=0.083, max_value=168, value=24.0, step=0.083)

col1, col2 = st.columns(2)

with col1:
    st.subheader("üìà Estad√≠sticas - Datos Enteros")
    stats = get_stats_int(hours)
    if stats is not None and not stats.empty:
        st.dataframe(stats, use_container_width=True)

with col2:
    st.subheader("üìâ Estad√≠sticas - Datos Flotantes")
    stats = get_stats_float(hours)
    if stats is not None and not stats.empty:
        st.dataframe(stats, use_container_width=True)
```

---

### Paso 6: Crear archivo `.env` para la App

**6.1. Crea `streamlit_app/.env`:**

```env
# Configuraci√≥n de Base de Datos
DB_HOST=localhost
DB_PORT=5432
DB_USER=user
DB_PASSWORD=password
DB_NAME=sensordata
```

---

### Paso 7: Probar la App Localmente

**7.1. Desde tu terminal, navega a la carpeta del proyecto:**

```bash
cd c:\Users\angel\OneDrive\Documents\IOT\U1-Activity-3.-MQTT-Data-Ingestion-and-Visualization
```

**7.2. Activa el entorno virtual (si tienes uno) o instala Streamlit:**

```bash
pip install streamlit plotly pandas psycopg2-binary sqlalchemy python-dotenv
```

**7.3. Ejecuta la aplicaci√≥n:**

```bash
streamlit run streamlit_app/app.py
```

Deber√≠as ver algo como:

```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

**7.4. Abre tu navegador en `http://localhost:8501`**

---

### Paso 8: Ejecutar con Docker (Opcional - para producci√≥n)

**8.1. Actualiza `docker-compose.yml` para que incluya el servicio streamlit:**

El archivo ya tiene una secci√≥n para streamlit:

```yaml
streamlit:
  build:
    context: ./streamlit_app
  ports:
    - "8501:8501"
  depends_on:
    - postgres
    - mosquitto
  environment:
    - DB_HOST=postgres
    - DB_PORT=5432
    - DB_USER=user
    - DB_PASSWORD=password
    - DB_NAME=sensordata
  networks:
    - data_pipeline_net
```

**8.2. Aseg√∫rate de que `streamlit_app/Dockerfile` est√© correcto:**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**8.3. Levanta los servicios con Docker:**

```bash
docker-compose up -d streamlit
```

**8.4. Accede en `http://localhost:8501`**

---

## üìÇ Estructura de Archivos Final

```
streamlit_app/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt          # ‚úÖ Debe existir
‚îú‚îÄ‚îÄ .env                     # ‚úÖ Crea este
‚îú‚îÄ‚îÄ app.py                   # ‚úÖ Crea este (app principal)
‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # ‚úÖ Crea este (vac√≠o)
‚îÇ   ‚îú‚îÄ‚îÄ page1_datos_en_vivo.py
‚îÇ   ‚îî‚îÄ‚îÄ page2_estadisticas.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # ‚úÖ Crea este (vac√≠o)
‚îÇ   ‚îî‚îÄ‚îÄ db_connection.py    # ‚úÖ Crea este (m√≥dulo de conexi√≥n)
‚îî‚îÄ‚îÄ styles/
    ‚îî‚îÄ‚îÄ custom.css          # Opcional
```

---

## üîå Conexi√≥n a la Base de Datos

### Desde tu m√°quina (desarrollo local):
```
Host: localhost
Puerto: 5432
Usuario: user
Contrase√±a: password
Base de datos: sensordata
```

### Desde Docker (dentro de docker-compose):
```
Host: postgres (nombre del servicio)
Puerto: 5432
Usuario: user
Contrase√±a: password
Base de datos: sensordata
```

El c√≥digo que te proporcion√© usa `localhost` por defecto, que funciona cuando ejecutas Streamlit localmente. Si lo corres en Docker, ajusta el `.env` a:

```env
DB_HOST=postgres
```

---

## ‚úÖ Checklist de Implementaci√≥n

- [ ] Paso 1: Verificar que Docker est√© corriendo
- [ ] Paso 2: Crear estructura de carpetas y archivos
- [ ] Paso 3: Crear `streamlit_app/utils/db_connection.py`
- [ ] Paso 4: Crear `streamlit_app/app.py`
- [ ] Paso 5: Crear p√°ginas adicionales (opcional)
- [ ] Paso 6: Crear `streamlit_app/.env`
- [ ] Paso 7: Probar localmente con `streamlit run streamlit_app/app.py`
- [ ] Paso 8: Probar con Docker (opcional)
- [ ] Paso 9: Validar que las gr√°ficas muestren datos reales
- [ ] Paso 10: Hacer commit a Git

---

## üêõ Troubleshooting

### Error: "ModuleNotFoundError: No module named 'streamlit'"
**Soluci√≥n**: Instala con `pip install streamlit`

### Error: "could not connect to server: Connection refused"
**Soluci√≥n**: 
- Verifica que PostgreSQL est√© corriendo: `docker-compose ps`
- Verifica que `DB_HOST` en `.env` sea correcto (localhost para dev, postgres para Docker)

### Error: "relation 'lake_raw_data_int' does not exist"
**Soluci√≥n**:
- Verifica que el subscriber est√© corriendo: `docker-compose logs subscriber`
- Verifica que PostgreSQL haya ejecutado `init.sql`: `docker-compose logs postgres_db`

### Dashboard sin datos
**Soluci√≥n**:
- Verifica que el publisher est√© publicando: `docker-compose logs subscriber`
- Espera a que acumule algunos segundos de datos
- Haz clic en "Refrescar" en la sidebar

---

## üìû Pr√≥ximos Pasos

1. ‚úÖ Implementa los archivos seg√∫n esta gu√≠a
2. ‚úÖ Prueba localmente
3. ‚úÖ Valida que las gr√°ficas muestren datos reales
4. ‚úÖ Mejora la UI/UX si lo deseas (colores, temas, etc.)
5. ‚úÖ Documenta cualquier cambio que hagas
6. ‚úÖ Comunica con el equipo cuando est√© listo

---

¬°Adelante, Dami√°n! üöÄ
