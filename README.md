# ğŸš€ OpenAQ Data Pipeline and Visualization Dashboard

Un sistema completo de ingesta de datos, almacenamiento y visualizaciÃ³n que consume datos reales de la API de OpenAQ, los procesa y los presenta en un dashboard interactivo de Streamlit.

**DiseÃ±ado como un proyecto final robusto que demuestra un pipeline de datos de punta a punta.**

## ğŸ“‹ Arquitectura del Sistema

El proyecto sigue una arquitectura de pipeline de datos moderna y desacoplada.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                â”‚      â”‚   Servicio de Ingesta (ETL) â”‚      â”‚                     â”‚      â”‚  Servicio de VisualizaciÃ³n â”‚      â”‚               â”‚
â”‚  OpenAQ API    â”œâ”€â”€â”€â”€â”€â–ºâ”‚     (Python / Docker)       â”œâ”€â”€â”€â”€â”€â–ºâ”‚   PostgreSQL        â”œâ”€â”€â”€â”€â”€â–ºâ”‚    (Streamlit / Docker)    â”œâ”€â”€â”€â”€â”€â–ºâ”‚ Usuario Final â”‚
â”‚ (Fuente Externa) â”‚      â”‚                             â”‚      â”‚   (Docker)          â”‚      â”‚                            â”‚      â”‚ (Navegador Web) â”‚
â”‚                â”‚      â”‚                             â”‚      â”‚                     â”‚      â”‚                            â”‚      â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Componentes Principales

### 1. **Fuente de Datos: OpenAQ API**
- **DescripciÃ³n**: API pÃºblica que provee datos de monitoreo de calidad del aire de estaciones a nivel mundial.
- **FunciÃ³n**: ActÃºa como la fuente de datos crudos para nuestro pipeline.
- **Seguridad**: El acceso requiere una API Key, gestionada de forma segura a travÃ©s de un archivo `.env`.

### 2. **Servicio de Ingesta (ETL)**
- **Contenedor**: `ingestion`
- **DescripciÃ³n**: Un script de Python (`run_publisher.py`) que se ejecuta en un bucle dentro de un contenedor Docker. Es el corazÃ³n del pipeline y realiza el proceso de **ExtracciÃ³n, TransformaciÃ³n y Carga (ETL)**.
- **Funcionamiento**: Se conecta a la API de OpenAQ, extrae los datos, los transforma a un formato adecuado y los carga en la base de datos PostgreSQL.

### 3. **Base de Datos PostgreSQL**
- **Contenedor**: `postgres_db`
- **DescripciÃ³n**: Base de datos relacional que almacena los datos de calidad del aire en un **modelo dimensional** (esquema de estrella), lo que optimiza las consultas analÃ­ticas.
- **Esquema**:
    - `dim_stations`: Almacena metadatos de las estaciones.
    - `dim_parameters`: Almacena metadatos de los contaminantes.
    - `fact_measurements`: Almacena cada mediciÃ³n individual.
- **InicializaciÃ³n**: El esquema se crea automÃ¡ticamente al iniciar el contenedor gracias al script `init.sql`.

### 4. **Dashboard de Streamlit**
- **Contenedor**: `streamlit_app`
- **DescripciÃ³n**: Una aplicaciÃ³n web interactiva para la visualizaciÃ³n y anÃ¡lisis de los datos.
- **Funcionalidades**:
    - **Vista General**: KPIs, serie temporal, mapa de la estaciÃ³n y tabla de datos crudos.
    - **AnÃ¡lisis Avanzado**: 4 grÃ¡ficas adicionales (Gauge, Barras, Heatmap, Box Plot) para descubrir patrones.
    - **Explorador SQL**: Una consola para ejecutar consultas `SELECT` personalizadas directamente sobre la base de datos.

---

## ğŸš€ Inicio RÃ¡pido (2 Pasos)

1.  **Configurar Variables de Entorno**:
    *   Renombra el archivo `.env.example` a `.env`.
    *   Abre el archivo `.env` y pega tu API Key de OpenAQ en la variable `OPENAQ_API_KEY`.

2.  **Iniciar todos los servicios con Docker Compose**:
    ```bash
    docker compose up --build
    ```
    *   El flag `--build` es importante para construir las imÃ¡genes con la configuraciÃ³n correcta la primera vez.

**Â¡Eso es todo!** El sistema estÃ¡ corriendo. El script de ingesta comenzarÃ¡ a poblar la base de datos y el dashboard estarÃ¡ disponible.

### Acceso a Servicios

- ğŸ“Š **Streamlit Dashboard**: [http://localhost:8501](http://localhost:8501)
- ğŸ—„ï¸ **PostgreSQL**: `localhost:5432` (usuario: `user`, contraseÃ±a: `password`, bd: `sensordata`)

## ğŸ“ Estructura del Proyecto Clave

```
U1_FinalProjectIoT_Dataset_Dashboard/
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de todos los servicios Docker
â”œâ”€â”€ init.sql                    # Script de inicializaciÃ³n de la BD
â”œâ”€â”€ .env                        # Archivo para tus variables de entorno (API Key, etc.)
â”œâ”€â”€ run_publisher.py            # Script principal del servicio de ingesta (ETL)
â”œâ”€â”€ Dockerfile                  # Define la imagen para el servicio de ingesta
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ Dockerfile              # Define la imagen para el servicio de Streamlit
â”‚   â”œâ”€â”€ app.py                  # CÃ³digo principal del dashboard
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ db_connection.py    # LÃ³gica para conectar Streamlit a la BD
â”‚
â””â”€â”€ [DocumentaciÃ³n]
    â”œâ”€â”€ README.md               # Este archivo
    â”œâ”€â”€ DISEÃ‘O_DB.md            # DescripciÃ³n detallada del esquema de la BD
    â”œâ”€â”€ CONSULTAS_AVANZADAS.md  # Ejemplos de queries SQL complejas
    â””â”€â”€ ...
```

## ğŸ”§ ConfiguraciÃ³n (`.env`)

AsegÃºrate de que tu archivo `.env` contenga lo siguiente:

```env
# API Key para la API de OpenAQ
OPENAQ_API_KEY=TU_API_KEY_AQUI

# ConfiguraciÃ³n de la Base de Datos (usada por los scripts y Streamlit)
DB_HOST=postgres_db
DB_PORT=5432
DB_NAME=sensordata
DB_USER=user
DB_PASSWORD=password
```

## ğŸ³ Comandos Docker Principales

```bash
# Construir e iniciar todos los servicios en segundo plano
docker compose up -d --build

# Ver logs de todos los servicios
docker compose logs -f

# Ver logs de un servicio especÃ­fico (ej. streamlit)
docker compose logs -f streamlit

# Detener todos los servicios
docker compose down

# Detener servicios y eliminar volÃºmenes de datos (reinicio limpio)
docker compose down --volumes
```

## ğŸ“Š SQL Queries de Ejemplo

Estas consultas se pueden ejecutar en la pestaÃ±a "Explorador SQL" del dashboard.

### Resumen por Contaminante
```sql
SELECT
    p.display_name AS contaminante,
    p.units AS unidades,
    COUNT(fm.value) AS total_mediciones,
    ROUND(AVG(fm.value)::numeric, 2) AS promedio_valor
FROM fact_measurements fm
JOIN dim_parameters p ON fm.parameter_id = p.id
GROUP BY p.display_name, p.units
ORDER BY contaminante;
```

### ComparaciÃ³n con MediciÃ³n Anterior
```sql
SELECT
    timestamp_utc,
    value AS valor_actual,
    LAG(value, 1) OVER (ORDER BY timestamp_utc) AS valor_anterior
FROM fact_measurements
WHERE parameter_id = 2 -- PM2.5
ORDER BY timestamp_utc DESC
LIMIT 100;
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "cannot allocate memory" durante `docker compose up --build`
- **Causa**: Docker no tiene suficiente RAM para compilar dependencias.
- **SoluciÃ³n**: Se ha optimizado el `Dockerfile` para no instalar `gcc`, lo que resuelve este problema. Si persiste, aumenta la memoria asignada a Docker Desktop en `Settings > Resources`.

### Dashboard sin datos o con el error "No hay parÃ¡metros disponibles"
- **Causa**: El script de ingesta aÃºn no ha cargado datos.
- **SoluciÃ³n**: Espera 1-2 minutos despuÃ©s de iniciar los contenedores para que el primer ciclo de ingesta se complete. Refresca la pÃ¡gina del dashboard.

### Error de ConexiÃ³n a la Base de Datos desde Streamlit
- **Causa**: El contenedor de Streamlit iniciÃ³ antes de que la base de datos estuviera lista.
- **SoluciÃ³n**: El `docker-compose.yml` estÃ¡ configurado con `depends_on` y `healthcheck` para evitar esto. Un `docker compose restart streamlit` deberÃ­a solucionarlo si ocurre.

## ğŸ“ Este Proyecto Demuestra
- âœ… DiseÃ±o de un pipeline de datos real (ETL).
- âœ… Consumo de una API externa (OpenAQ).
- âœ… DiseÃ±o de base de datos con un modelo dimensional (esquema de estrella).
- âœ… OrquestaciÃ³n de microservicios con Docker Compose.
- âœ… Desarrollo de un dashboard interactivo y analÃ­tico con Streamlit.
- âœ… Uso de SQL avanzado (JOINs, Funciones de Ventana, Agregaciones).

---

**Estado**: âœ… Listo para ProducciÃ³n (Nivel Educativo)
**Ãšltima actualizaciÃ³n**: Febrero 2026
**DiseÃ±o**: Proyecto Final de IoT

Â¡Listo para desplegar y presentar! ğŸ‰
