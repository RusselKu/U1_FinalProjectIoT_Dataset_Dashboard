# ğŸ“„ Reporte TÃ©cnico del Proyecto: Ingesta y VisualizaciÃ³n de Datos IoT con MQTT y Streamlit

**Fecha:** 02 de Febrero de 2026
**Autores:** [Tu Nombre], [Nombre de Tu CompaÃ±ero de LaTeX]
**Estado:** âœ… Backend Completo, Frontend Funcional, DocumentaciÃ³n Preliminar Lista

---

## ğŸš€ 1. Resumen Ejecutivo

Este documento detalla la implementaciÃ³n de un sistema integral de ingesta y visualizaciÃ³n de datos de Internet de las Cosas (IoT). El proyecto utiliza un Publisher para simular la generaciÃ³n de datos, un broker MQTT (Mosquitto) para la mensajerÃ­a, un Subscriber para almacenar los datos en una base de datos PostgreSQL, y un dashboard interactivo desarrollado con Streamlit para la visualizaciÃ³n en tiempo real. El objetivo es proveer una plataforma robusta y escalable para el monitoreo de datos IoT.

---

## ğŸ“‹ 2. Arquitectura del Sistema

El sistema sigue una arquitectura modular y desacoplada, facilitando el mantenimiento y la escalabilidad.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Publisher          â”‚
â”‚  (Genera datos)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  MQTT Topics â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚lake/raw/int  â”‚
    â”‚lake/raw/floatâ”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Mosquitto       â”‚
    â”‚ (Broker MQTT)   â”‚
    â”‚ Port 1883       â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Subscriber       â”‚
    â”‚ (Docker Service) â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PostgreSQL           â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ lake_raw_data_int    â”‚
    â”‚ â€¢ lake_raw_data_float  â”‚
    â”‚ â€¢ events_log           â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Streamlit Dashboard â”‚
    â”‚  http://localhost   â”‚
    â”‚        :8501        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Componentes Clave:**

*   **Publisher (Python):** Simula un dispositivo IoT, generando valores aleatorios (enteros y flotantes) y publicÃ¡ndolos en tÃ³picos MQTT especÃ­ficos (`lake/raw/int`, `lake/raw/float`).
*   **Mosquitto MQTT Broker (Docker):** ActÃºa como el centro de mensajerÃ­a, recibiendo los datos del Publisher y distribuyÃ©ndolos a los suscriptores.
*   **Subscriber (Python, Docker Service):** Escucha los tÃ³picos de Mosquitto, procesa los mensajes y los inserta en la base de datos PostgreSQL.
*   **PostgreSQL Database (Docker):** Almacena los datos IoT en tablas separadas para enteros (`lake_raw_data_int`) y flotantes (`lake_raw_data_float`), con campos de ID, tÃ³pico, valor y timestamp.
*   **Streamlit Dashboard (Python):** Se conecta a la base de datos PostgreSQL para recuperar los datos y los visualiza en tiempo real a travÃ©s de grÃ¡ficos interactivos y estadÃ­sticas.

---

## âš™ï¸ 3. ConfiguraciÃ³n del Entorno

Para levantar el proyecto, se requieren los siguientes prerrequisitos y pasos:

### 3.1. Prerrequisitos

*   **Docker Desktop:** Instalado y en ejecuciÃ³n (incluye Docker Engine y Docker Compose).
*   **Python 3.11+:** Instalado localmente.
*   **Git:** Para clonar el repositorio.

### 3.2. ClonaciÃ³n del Repositorio

```bash
git clone <URL_DEL_REPOSITORIO> U1-Activity-3.-MQTT-Data-Ingestion-and-Visualization
cd U1-Activity-3.-MQTT-Data-Ingestion-and-Visualization
```

### 3.3. ConfiguraciÃ³n de Variables de Entorno para Streamlit

El dashboard de Streamlit requiere credenciales de base de datos que se configuran a travÃ©s de un archivo `.env` en el directorio `streamlit_app/`.

1.  AsegÃºrate de que el archivo `streamlit_app/.env` exista con el siguiente contenido:
    ```env
    DB_HOST=localhost
    DB_PORT=5432
    DB_USER=user
    DB_PASSWORD=password
    DB_NAME=sensordata
    ```
    (Nota: Se usa `localhost` para la ejecuciÃ³n local de Streamlit, conectÃ¡ndose al puerto expuesto de PostgreSQL).

---

## ğŸ“¥ 4. Flujo de Datos: Publisher a PostgreSQL

Esta secciÃ³n describe cÃ³mo los datos se generan, transmiten y almacenan en la base de datos.

### 4.1. Inicio de Servicios Docker (Backend)

Todos los servicios de backend (Mosquitto, PostgreSQL y Subscriber) se orquestan con Docker Compose.

```bash
# Desde la raÃ­z del proyecto:
docker-compose down --volumes --rmi all # Limpieza completa (opcional, pero recomendada)
docker-compose up -d --build             # Iniciar todos los servicios en segundo plano
```

**VerificaciÃ³n de Servicios:**
```bash
docker-compose ps
```
**[CAPTURAR PANTALLA 1: Salida de `docker-compose ps` mostrando los servicios `mosquitto`, `postgres_db` y `subscriber` como "Up"]**

### 4.2. EjecuciÃ³n del Publisher

El script `run_publisher.py` genera datos aleatorios y los envÃ­a al broker MQTT. Debe ejecutarse en una terminal separada y permanecer activo para que haya flujo de datos.

```bash
# Desde la raÃ­z del proyecto, en una TERMINAL NUEVA:
python run_publisher.py
```

### 4.3. VerificaciÃ³n de Ingesta de Datos (Logs del Subscriber)

El Subscriber recibe los datos del Publisher y los inserta en PostgreSQL. Los logs del Subscriber confirman la recepciÃ³n e inserciÃ³n de datos.

```bash
# Desde la raÃ­z del proyecto, en OTRA TERMINAL (o donde levantaste los servicios):
docker-compose logs subscriber -f
```
Se deben observar lÃ­neas como las siguientes, indicando la inserciÃ³n exitosa de datos:

```
subscriber  | ... INFO âœ… INT inserted: topic=lake/raw/int, value=...
subscriber  | ... INFO âœ… FLOAT inserted: topic=lake/raw/float, value=...
```
**[CAPTURAR PANTALLA 2: Terminal mostrando el log del subscriber con varias lÃ­neas de "INT inserted" y "FLOAT inserted"]**

---

## ğŸ“Š 5. ImplementaciÃ³n y EjecuciÃ³n del Dashboard Streamlit

El dashboard, implementado por DamiÃ¡n, visualiza los datos en tiempo real extraÃ­dos de PostgreSQL.

### 5.1. Archivos Clave del Dashboard

Los siguientes archivos fueron creados o actualizados para el dashboard:

*   **`streamlit_app/.env`:** ConfiguraciÃ³n de credenciales de la base de datos.
*   **`streamlit_app/utils/__init__.py`:** Archivo vacÃ­o que marca `utils` como un paquete Python.
*   **`streamlit_app/utils/db_connection.py`:** MÃ³dulo para establecer la conexiÃ³n a PostgreSQL y funciones para consultar datos enteros, flotantes y sus estadÃ­sticas.
*   **`streamlit_app/app.py`:** Archivo principal de la aplicaciÃ³n Streamlit, que define la interfaz de usuario, los grÃ¡ficos (Plotly) y la lÃ³gica de visualizaciÃ³n.

### 5.2. InstalaciÃ³n de Dependencias

AsegÃºrate de que las dependencias de Python para Streamlit estÃ©n instaladas.

```bash
# Desde la raÃ­z del proyecto o desde streamlit_app/:
pip install streamlit plotly pandas psycopg2-binary python-dotenv
```

### 5.3. EjecuciÃ³n del Dashboard Streamlit

Para iniciar la aplicaciÃ³n Streamlit, se recomienda usar una terminal como PowerShell o CMD debido a problemas de interacciÃ³n con MINGW64.

```bash
# Desde el directorio streamlit_app/:
cd C:/Users/angel/OneDrive/Documents/IOT/U1-Activity-3.-MQTT-Data-Ingestion-and-Visualization/streamlit_app
python -m streamlit run app.py --server.port 8501 --server.address 0.0.0.0 --browser.gatherUsageStats false --browser.serverAddress localhost
```
Una vez ejecutado, el dashboard deberÃ­a abrirse automÃ¡ticamente en tu navegador en `http://localhost:8501`.

---

## âœ… 6. VerificaciÃ³n y Resultados del Dashboard

El dashboard de Streamlit presenta dos pestaÃ±as principales: "Datos en Vivo" y "EstadÃ­sticas", ademÃ¡s de una pestaÃ±a de "InformaciÃ³n".

### 6.1. PestaÃ±a "Datos en Vivo"

Esta pestaÃ±a muestra grÃ¡ficos de series de tiempo para datos enteros y flotantes, actualizÃ¡ndose con los datos mÃ¡s recientes de la base de datos.

*   **GrÃ¡fica de Datos Enteros (LÃ­nea Azul):** Visualiza la evoluciÃ³n de los valores enteros a lo largo del tiempo.
*   **GrÃ¡fica de Datos Flotantes (LÃ­nea Naranja):** Visualiza la evoluciÃ³n de los valores flotantes a lo largo del tiempo.
*   **Ãšltimos Registros:** Se puede expandir para ver una tabla con los Ãºltimos 10 registros de cada tipo.

**[CAPTURAR PANTALLA 3: Dashboard de Streamlit en la pestaÃ±a "Datos en Vivo", mostrando ambas grÃ¡ficas con datos y los Ãºltimos registros expandidos.]**

### 6.2. PestaÃ±a "EstadÃ­sticas"

Esta pestaÃ±a ofrece un resumen estadÃ­stico de los datos ingeridos.

*   **MÃ©tricas para Datos Enteros y Flotantes:** Incluye el total de registros, promedio, valor mÃ­nimo, valor mÃ¡ximo y desviaciÃ³n estÃ¡ndar.
*   **Filtro de Rango de Tiempo:** En la barra lateral, se puede seleccionar un rango de tiempo (ej. "Ãšltima 1 hora", "Ãšltimos 7 dÃ­as") para analizar datos especÃ­ficos. El botÃ³n "Refrescar Datos" actualiza las grÃ¡ficas y estadÃ­sticas segÃºn el filtro.

**[CAPTURAR PANTALLA 4: Dashboard de Streamlit en la pestaÃ±a "EstadÃ­sticas", mostrando todas las mÃ©tricas. AsegÃºrate de que el filtro de rango de tiempo en la barra lateral sea visible.]**

---

## ğŸ’¡ 7. Conclusiones

El proyecto ha logrado establecer un pipeline de datos IoT funcional, desde la simulaciÃ³n de sensores hasta la visualizaciÃ³n interactiva. La arquitectura basada en Docker y componentes desacoplados demuestra robustez y facilidad de gestiÃ³n. A pesar de los desafÃ­os iniciales en la configuraciÃ³n del entorno (como los problemas de interacciÃ³n en MINGW64), se logrÃ³ la integraciÃ³n exitosa de todos los componentes. El dashboard de Streamlit proporciona una herramienta intuitiva para el monitoreo en tiempo real, validando la eficacia del sistema.

---

## â­ï¸ 8. PrÃ³ximos Pasos

Este documento servirÃ¡ como base para la creaciÃ³n de un informe tÃ©cnico formal en LaTeX. Tu compaÃ±ero deberÃ¡:

1.  Tomar las capturas de pantalla indicadas en este documento.
2.  Integrar el contenido de este Markdown en el formato LaTeX IEEE, aÃ±adiendo cualquier detalle tÃ©cnico adicional que considere relevante para el informe final.
3.  Asegurarse de que las imÃ¡genes (capturas de pantalla) se inserten correctamente en el reporte LaTeX.

---
